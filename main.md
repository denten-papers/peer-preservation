---
title: Book Piracy as Peer Preservation
bibliography: bib.bib
---

> Literature is the secretion of civilization, poetry of the ideal. That is why literature is one of the wants of societies. That is why poetry is a hunger of the soul. That is why poets are the first instructors of the people. That is why Shakespeare must be translated in France. That is why Molière must be translated in England. That is why comments must be made on them. That is why there must be a vast public literary domain. That is why all poets, all philosophers, all thinkers, all the producers of the greatness of the mind must be translated, commented on, published, printed, reprinted, stereotyped, distributed, explained, recited, spread abroad, given to all, given cheaply, given at cost price, given for nothing.
[@hugo_works_1907, p. 230]

The big money (and the bandwidth) in online media is in film, music, and software. Text is less profitable for copyright holders; it is cheaper to duplicate and easier to share. Consequently, the issues surrounding the unsanctioned sharing of print material receive less press and scant academic attention. And yet the establishment of the "vast public literary domain" is an ideal that transcends piracy. Writers, librarians, and political activists from Victor Hugo to Leo Tolstoy and Andrew Carnegie have long argued for unrestricted access to information as a form of a public good essential to civic engagement. In that sense, people participating in online book exchanges enact the role closer to that of a public librarian than that of a bootlegger or a plagiarist. Book piracy cannot then be dismissed as mere search for free entertainment. Under the conditions of "digital disruption,"^[http://web.archive.org/web/20140110160431/http://go.proquest.com/libraries-at-the-center-of-the-digital-disruption] when the traditional institutions of knowledge sharing—the library, the university, the newspaper, and the publishing house—feel themselves challenged and transformed by the internet, we look to online book sharing communities for lessons in participatory governance, technological innovation, and economic sustainability.

The primary aim of this paper is ethnographic and descriptive: to study and to learn from a particular ecosystem of texts, people, and technologies—an ecosystem that constitutes one of the largest digital libraries in the world, rivaling *Google Books*, *Hathi Trust*, *Europeana*, and similarly legitimized digital libraries around the world.[^LN0] In doing so, we begin broaching the questions of scope and impact. We would like to ask: Who? Where? and Why? What kind of people distribute books online? What motivates their activity? What technologies enable the sharing of print? And what can we learn from them? Our secondary aim is to begin the work of contextualizing that activity historically and theoretically. The traditional story of peer production is one of altruistic participation. But the very history of the public library is one that combines the impulse to share and to protect. To paraphrase @derrida_archive_1995 writing in "Archive Fever," the archive shelters memory just as it shelters itself from memory. We encompass this dual dynamic under the term of "peer preservation," where the concepts of "peer" and "preservation" denote social and technological mechanisms that can work against each other.

[^LN0]: This particular library is but one of many similarly peer produced pirated book archives from around the world.

### Ethics disclaimer
Research for this paper was conducted under the aegis of p\*, an academic research collective exploring the impact of peer-to-peer file sharing on the spread of knowledge around the world.^[http://p\*.org. Hashed for peer review only.] One the lab's first tasks was to discuss the ethics of piracy research. The conversation involved students, faculty, librarians, and informal legal council. Our major concern was neutrality: to avoid endangering the communities that we study and to protect the members of the lab from potential infringement. Following a frank discussion and several iterations, we drafted an ethics charter that continues to inform our work today. The charter contains the following provisions:

- When possible, remain neutral. We neither condone nor condemn piracy and copyright.
- We protect our sources and do not retain any identifying personal information.
- We strive for transparency in sharing our methodology, data, and findings with the widest possible audience.
- Credit where credit is due. Our work is clearly attributed to everybody involved.
- We limit our usage of licensed material to the analysis of metadata, with results used for non-commercial, nonprofit, educational purposes.
- Lab participants commit to abiding by these principles as long as they remain active members of the research group.

In accordance with these principles and following the practice of scholars like @bodo_set_2012, @lobato_cyberlocker_2013 and @priest_future_2006, we redact the names of file sharing services and user names, where such names are not made explicitly public elsewhere.

### Methods
Academic literature tends to view piracy on the continuum between free culture and copyright. On the one side, the argument is for redressing the global imbalance of access to information^[@benkler_wealth_2006, p. 442; @castells_communication_2007, p. 251; @lessig_free_2004; @shirky_here_2008, p. 153] and in support of an informed reading public as a prerequisite for sustainable, democratic deliberation^[@benkler_wealth_2006, p. 92; @schuler_information_2004; @dimaggio_social_2001, p. 320; @papacharissi_virtual_2002, p. 22]. On the other side, the argument is often made for the long-term conservancy of the cultural sphere, which (according to this view) must offer proper economic incentive to content creators in order to thrive.^[See @calandrillo_economic_1998, p. 306; @cohen_creativity_2006; @hughes_philosophy_1988, p. 303 for further discussion.] 

It is our contention that grassroots file sharing practices cannot be understood solely in terms of access and intellectual property. Our field work shows that while some members of the book sharing community participate for activist or ideological reasons, others do so as collectors, preservationists, curators, or simply readers. Despite romantic notions to the contrary, reading is a social and mediated activity. The reader encounters texts in conversation, through a variety of physical interfaces and within an ecosystem of overlapping communities, each projecting their own material contexts, social norms, and ideologies. A technician who works in a biology laboratory, for example, may publish closed-access peer-review articles by day, as part of his work collective, and release terabytes of published material by night, in the role of a moderator for an online digital library. Our approach then, is to capture some of the complexity of such an ecosystem, particularly in the liminal areas where people, texts, and technology converge.

### Big picture
Conceptually, the recent history of online book sharing and unsanctioned, "shadow" libraries^[@liang_shadow_2012] can roughly be divided into two periods. The first is characterized by local, ad-hoc peer-to-peer document exchanges and the subsequent growth of centralized content aggregators. Following trends in the development of the web as a whole, shadow libraries of the second period are characterized by communal governance and distributed infrastructure. Of course all infrastructure is social to an extent. Even private library collections cannot be said to be the work of a single individual. Collective forces shape the books themselves, the shelves, and the cognitive scaffolding that supports reading and interpretation. Yet, there is a palpable difference in both the administrative and the architectural structures governing private collections, public libraries, and torrent trackers (like *Pirate Bay*).^[http://thepiratebay.se/] Shadow libraries of the first period resemble a private collection in that they often emanate from a single authoritative source--a site of collection and distribution associated with an individual collector, sometimes explicitly. The library of Maxim Moshkov, for example, established in 1994 and still thriving at *lib.ru*, is one of the most visible collections of that kind. Despite their success, such libraries are limited in scale by the means and efforts of a few individuals. Due to their centralized architecture they are also susceptible to legal challenges from copyright owners and to state intervention. Shadow libraries responded to these problems by distributing labor, responsibility, and infrastructure, resulting in a system that is more robust, more redundant, and more resistant to any single point of failure or control.

### Fall of *Gigapedia*
The case of *Gigapedia* (later *library.nu*) and its related file hosting service *ifile.it* illustrates the successes and failures of the centralized digital library model. Arguably among the largest and most popular virtual libraries online in the period of 2009-2011, the sites were operated by Irish nationals[^LN3] on domains registered in Italy and on the island state of Niue, with servers on the territory of Germany and Ukraine. At its peak, *library.nu* (LNU) hosted more than 400,000 books and was purported to make an "estimated turnover of EUR 8 million (USD 10,602,400) from advertising revenues, donations and sales of premium-level accounts," at least according to a press release made by the International Publishers Association (IPA).[^LN1]

![Archived version of library.nu, circa 12/10/2010](figures/figure-1.jpg)

Its apparent popularity notwithstanding, *Gigapedia* was supported by relatively simple architecture, likely maintained by a single developer / administrator. The site itself consisted of a catalog of digital books and related metadata, including title, author, year of publication, number of pages, description, category classification, and a number of boolean parameters (whether the file is bookmarked, paginated, vectorized, is searchable, and has a cover). The catalog also contained a link to *ifile.it*, a "cyberlocker" service that hosted the actual files themselves.

On the 15th of February, 2012 the IPA in conjunction with a consortium of international publishing houses,[^LN2] served a judicial cease-and-desist orders on both sites in a Munich court with the help of the German law firm Lausen Rechtsanwalte.  Seventeen injunctions were sought in Ireland, with the consequent voluntary shut-down of both domains, which for a brief time redirected visitors first to *Google Books* and then to *Blue Latitudes*, a *New York Times* bestseller about pirates, for sale on *Amazon*. The relatively brief, by library standards, existence of LNU underscores the weakness of the single-source digital library model. The site flourished as long as it did not attract the ire of the publishing industry. A lack of redundancy in the site's administrative structure paralleled the lack of redundancy on the server level. Once the identity of the operators was established--via Paypal receipts, according to a partner at Lausen Rechtsanwalte--the entire library was forced to shut down^[@losowsky_book_2012]. The single point of origin also proved to be the single point of failure for the entire system.

[^LN1]: http://web.archive.org/web/20140110160254/http://www.internationalpublishers.org/ipa-press-releases/286-publishers-strike-major-blow-against-internet-piracy
[^LN2]: Including the German Publishers and Booksellers Association, Cambridge University Press, Georg Thieme, Harper Collins, Hogrefe, Macmillan Publishers Ltd., Cengage Learning, Elsevier, John Wiley & Sons, The McGraw-Hill Companies, Pearson Education Ltd., Pearson Education Inc., Oxford University Press, Springer, Taylor & Francis, C.H. Beck as well as Walter De Gruyter. The legal proceedings are also supported by the Association of American Publishers (AAP), the Dutch Publishers Association (NUV), the Italian Publishers Association (AIE) and the International Association of Scientific Technical and Medical Publishers (STM).
[^LN3]: The injunctions name I\* and F\* N\* (also known as Smiley).

Jens Bammel, Secretary General of the IPA, called the action "an important step towards a more transparent, honest and fair trade of digital content on the Internet,"^[http://web.archive.org/web/20140110160254/http://www.internationalpublishers.org/ipa-press-releases/286-publishers-strike-major-blow-against-internet-piracy] while the rest of the internet mourned the passage of "the greatest, largest and the best website for downloading eBooks"^[http://archive.is/g205] and the burning of the "modern Library of Alexandria."^[https://web.archive.org/web/20140113135846/http://breakingculture.tumblr.com/post/17697325088/gigapedia-rip] Readers from around the world flocked to sites like *Reddit* and *TorrentFreak* to express their support and anger. A reader of *TorrentFreak* writes:

> I live in Macedonia (the Balkans), a country where the average salary is somewhere around 200eu, and I’m a student, attending a MA degree in communication sci. [...] where I come from the public library is not an option. [...] Our libraries are so poor, mostly containing 30year or older editions of books that almost never refer to the field of communication or any other contemporary science. My professors never hide that they use sites like library.nu [...] Original textbooks [...] are copy-printed handouts of some god knows how obtained original [...] For a country like Macedonia and the Balkans region generally THIS IS A APOCALYPTIC SCALE DISASTER! I really feel like the dark age is just around the corner these days.^[https://web.archive.org/web/20140110050710/http://torrentfreak.com/book-publishers-shut-down-library-nu-and-ifile-it-120215]

A similar comment on *Reddit* reads:

> This is the saddest news of the year...heart-breaking...shocking...I was so attached to this site...I am from a third world country where buying original books is way too expensive if we see currency exchange rates...library.nu was a sea of knowledge for me and I learnt a lot from it [...] RIP library.nu...you have ignited several minds with free knowledge.^[<https://web.archive.org/web/20140110050450/http://www.reddit.com/r/trackers/comments/ppfwc/librarynu_admin_the_website_is_shutting_down_due>]

Another redditor writes:

> This was an invaluable resource for international academics. The catalog of libraries overseas often cannot meet the needs of researchers in fields not specific to the country in which they are located. My doctoral research has taken a significant blow due to this recent shutdown [...]  Please publishers, if you take away such a valuable resource, realize that you have created a gap that will be filled. This gap can either be filled by you or by us.^[<https://web.archive.org/web/20140110050450/http://www.reddit.com/r/trackers/comments/ppfwc/librarynu_admin_the_website_is_shutting_down_due>]

Another concludes:

> This just makes me want to start archiving everything I can get my hands on.^[<https://web.archive.org/web/20140110050450/http://www.reddit.com/r/trackers/comments/ppfwc/librarynu_admin_the_website_is_shutting_down_due>]

These anecdotal reports confirm our own experiences of studying and teaching at universities with a diverse audience of international students, who often recount a similar personal narrative. *Gigapedia* and analogous sites seem to fulfill an unmet need in the international market, redressing global imbalances of pricing and access to information--a point made in the report (released by the American Assembly in 2011) on media piracy in emerging economies^[@karaganis_media_2011, p. i]. 

But, being a single-source, cyberlocker-based service, *Gigapedia* failed to leverage the good will of the community. As @lobato_cyberlocker_2013 write in their paper on cyberlocker-based media distribution systems, cyberlockers take an "instrumental view" of file sharing, where "no attempt is made to curate, organize, or archive the hosted content."^[@lobato_cyberlocker_2013, p. 9] In the words of the authors, the cyberlocker economy "does not foster collaboration or co-creation"^[@lobato_cyberlocker_2013, p. 9] making it difficult to support such non-transformative use ethically, and, as we would add, making it impossible to launch a meaningful "rescue" effort to preserve the archive. "This underscores the structural instability of file-sharing communities"^[@lobato_cyberlocker_2013, p. 7] write @lobato_cyberlocker_2013. It would be more precise to say that the cyberlocker story underscores the structural instability of single-source media archives (and not file sharing communities in general). Although bereaved readers were concerned about the irrevocable loss of a valuable resource, digital libraries that followed built a model of file sharing that is more robust, more transparent, and more participatory than their *Gigapedia* / LNU predecessors.

### Rise of Aleph
In parallel with the development of *Gigapedia* / *library.nu*, Russian enthusiasts started work on a meta-library of sorts, under the name of Aleph. Records of Aleph's activity go back at least as far as 2009. Colloquially known as "prospectors," the volunteer members of the Aleph community began by aggregating library collections widely available on the gray market, with an emphasis on academic and technical literature in Russian and English. A similar project (FB) congealed around fiction.

![DVD copy of "Traum's library" advertising "more than 167,000 books" in fb2 format. Similar DVDs sell for around 1,000 RUB ($25-30 US) on the streets of Moscow.](figures/figure-2.jpg)

At its inception, Aleph compiled several "home-grown" archives:

- *KoLXo3*, a collection of scientific texts that was at one time distributed on 20 DVDs, overlapping with early Gigapedia efforts;
- *mexmat*, a library collected by the members of Moscow State University's Department of Mechanics and Mathematics for internal use, originally distributed through private FTP servers;
- *Homelab*, *Ihtik*, and *Ingsat* libraries;
- the Foreign Fiction archive collected from IRC #\* 2003.09-2011.07.09 and the Internet Library;
- the *Great Science Textbooks* collection and, later, over 20 smaller miscellaneous archives.^[GN/viewtopic.php?f=8&t=169; GN/viewtopic.php?f=17&t=299]

The founders conceived of the project 1) as a "front-end" server software for searching and downloading books, 2) as an online forum for enthusiasts willing to contribute to the project, and 3) as a "back-end" archive of documents, primarily in .pdf and .djvu formats.^[GN/viewtopic.php?f=17&t=299] "What do we do?" writes one of the early volunteers (in 2009) on the topic of "Outcomes, Goals, and Scope of the Project." He answers: "we loot sites with ready-made collections," "sort the indices in arbitrary normalized formats," "for uncatalogued books we build a 'technical index': name of file, size, hashcode," "write scripts for database sorting after the initial catalog process," "search the database," "use the database for the construction of an accessible catalog," "build torrents for the distribution of files in the collection."^[GN/viewtopic.php?f=8&t=169. Quotes from GN in this article are translated from Russian by the authors, unless otherwise noted.] But, "everything begins with the forum," in the words of another founding member.^[GN/viewtopic.php?f=8&t=6999&p=41911] Aleph, the very name of the group, reflects the aspiration to develop a "platform for the inception of subsequent and more user-friendly" libraries--a platform "useful for the developer, the reader, and the librarian."^[GN/viewtopic.php?f=8&t=757]

![Aleph anatomy](figures/figure-3.jpg)

It should become apparent from studying Figure 3 that Aleph's innovation over LNU lies not in technological advancement, but in system architecture. Where LNU relied on proprietary server software, Aleph built a freely available server, which enabled others to mirror the site easily. The server was written by d\* from www.l\*.com (UZ), utilizing a codebase common to several similar large book-sharing communities. The initial organizational efforts happened on a sub-forum of a popular torrent tracker (RR). Fifteen founding members reached a majority decision to start hashing the files names comprising the server's back-end (using the MD5 message-digest algorithm).[^LN4] This was done both to weed out duplicates and to discourage direct (file system-level) browsing of the archive.^[See GN/viewtopic.php?f=8&t=55kj and GN/viewtopic.php?f=8&t=18&sid=936] Instead, the books were meant to be accessed through the front-end "librarian" interface, which added a layer of well-formed meta-data, subject areas, and full-text search tools. 

[^LN4]: For information on cryptographic hashing see @gauravaram_cryptographic_2010.

But, it is the community, not software that lies at the heart of the project. Volunteers coordinate their efforts asynchronously, by the means of a simple online forum (using *phpBB* software), open to all interested participants. Important issues related to the governance of the project--decisions about new hardware upgrades, software design, and the direction of the archive--receive thorough public review. For example, at one point, the group was worried about its visibility on *Google*. On the one hand, they wanted the site to remain open for general participation in their services. On the other hand, they didn't want to attract unwanted attention by the authorities. The issue was resolved when a member suggested delisting the website by altering the *robots.txt* configuration file to block *Google* crawlers.^[GN/viewtopic.php?f=8&t=714] Consequently, the site would become invisible to *Google*, while remaining freely accessible via a direct link. 

Finally, instead of relying on cyberlocker-type, single-server file sharing model, members of the Aleph community made an early decision to release canonical versions of the archive (in chunks) via *BitTorrent*--a distributed protocol for file sharing--and to rely on open rather than closed (by-invitation-only) trackers. The *BitTorrent* network serves as the archive's de facto backup repository. True to the initial conception of the project, such architecture enables further development of yet more advanced library ecosystems, which can use Aleph torrents to seed the beginnings of their own collections.

By March of 2009 these efforts resulted in approximately 79k volumes or around 180gb of data.^[GN/viewtopic.php?f=8&t=47] By December of the same year, the moderators began talking about a terabyte, 2tb in 2010, and around 7tb by 2011.^[GN/viewtopic.php?f=17&t=175&hilit=RR&start=25] By 2012, the core group of "prospectors" grew to 1,000 registered users. Aleph's main mirror received over a million page views per month and about 40,000 unique visits per day.^[GN/viewtopic.php?f=17&t=104&start=450] An online eBook piracy report estimates a combined total of a million unique visitors per day for Aleph and its mirrors.^[URL redacted; These numbers should be taken as a very rough estimate because 1) we do not consider Alexa to be a reliable source for web traffic and 2) some of the other figures cited in the report are suspicious. For example, Aleph has a relatively small archive of foreign fiction, at odds with the reported figure of 800,000 volumes.] As of January 2014, the Aleph catalog contains over a million books (1,021,000) and over 15 million academic articles, "weighing in" at just under 10tb. Most remarkably, one of the world's largest digital libraries operates on an annual budget of $1,900 US.^[GN/viewtopic.php?f=17&t=7061]

### Problems with distributed infrastructure
Unlike its predecessors, the diffuse nature of the project makes it resilient to any single point of failure, whether in the form of server malfunction, or in the form of legal pressure. Should Aleph servers go offline, the archive would survive "in the cloud" of the *BitTorrent* network. Should the forum (GN) close, another online forum could easily take its place. And should the Aleph "library" distribution portal itself go dark, other mirrors would quickly take its place.

*BitTorrent* protocol. At its bare minimum (as it was described in the original specification by Bram Cohen)^[http://web.archive.org/web/20140613190300/http://www.bittorrent.org/beps/bep_0003.html] the protocol involves a "seeder," someone willing to share something it its entirety; a "leecher," someone downloading shared data; and a centralized torrent "tracker" which would coordinate the activity between seeders and leechers. The power of *BitTorrent* comes from shifting the burden of sharing from the individual seeder to a "swarm" of leechers. The first leecher joining the network will get all of his data from the seeder directly. But the second leecher will receive some bits from the original seeder and some from the first leecher, in a non-linear, asynchronous fashion. When downloading from the *BitTorrent* network, a peer may get some bits from the beginning of the document, some from the middle, and some from the end from different members of the swarm. The torrent client (a local application) can then reassemble the pieces into a completed file, while the torrent tracker does some work to coordinate the activity--keeping track of bits that have already been downloaded and bits that are still needed from someone in the swarm. Having received the whole document, a leecher now has the option to become a seeder, by sharing with the remaining swarm (who only have partial copies), or to go offline and chose not to share.[^LN5] 

Early in 2008, Cohen extended the protocol to make use of a "distributed sloppy hash table" (DHT) for storing peer locations without resorting to a central tracker. In effect, each peer maintains a small routing table pointing to a handful of nearby peer locations. The DHT turns each peer into a tracker of sorts, however "sloppy" and imperfect. By these means, each to location of each peer can be discovered by queerying November of 2008, Pirate Bay, one of the largest of such servers, announced the shutting down of its tracker in favor of Distributed Hash Tables (DHT) and Magnet Links.^

[^LN5]: For more information on *BitTorrent*, see @cohen_incentives_2003; @salmon_simulating_2008.

The distributed model is not without its problems, however. The first challenge follows from the fact that ad-hoc distribution methods favor popular files, which are seeded and leeched by many people at once, which works well for Hollywood blockbusters, but less well for specialized scientific literature of the sort found in the Aleph archive. As one member writes on the GN forum, "unpopular files are in danger of become inaccessible."^[GN/viewtopic.php?f=8&t=6999] Aleph combats the problem of dying torrents by renting a "seedbox"--a server dedicated to keeping the less popular seeds alive, preserving the availability of the collection. The server currently in production can serve up to 12tb of data speeds of 100-800 megabits per second. Other file sharing communities address the issue by enforcing a certain download to upload ratio on members of their network.

The lack of anonymity is the second problem intrinsic to the *BitTorrent* protocol. Peers sharing bits directly expose their IP address to each other and to the server coordinating their activity.[^LN6] Legitimate copyright holders and copyright "trolls" alike have used this vulnerability to bring lawsuits against individual sharers in court.^[@ernesto_us_2011]

[^LN6]: Various technologies exist to aid user in retaining their anonymity.

These two challenges are further exacerbated in the case of Aleph, which uses *BitTorrent* to distribute parts of the archive, and not individual files. (The individual files are rather available from Aleph mirrors directly). These parts are relatively large--around 40-50 megabytes each. Long-term sustainability of Aleph torrent swarm therefore requires a very special user, a user interested in downloading the archive as a whole (to make a mirror, for example) and one who has the hardware, the technical expertise, and the internet connection required to sustain this activity.

### Peer preservation
Who are the contributing members of this community? And why do they participate? In light of the challenges and the effort involved, we cannot view their activity as piracy, understood in conventional terms of financial gain, theft, or profiteering. The day-to-day labor of the core group is much more comprehensible as a mode of commons-based peer production, which is, in the canonical definition, work made possible by a "networked environment," "radically decentralized, collaborative, and nonproprietary; based on sharing resources and outputs among widely distributed, loosely connected individuals who cooperate with each other without relying on either market signals or managerial commands."^[@benkler_wealth_2006 p. 60] Yet, unlike free software movement or *Wikipedia* (the common examples of peer production), the "product" of Aleph's labor edges on the side of distribution, rather than authorship. In that sense, such activity is instantly recognizable as the work of a library, in what we dub as "peer preservation." The distinction from peer production is important in that the history of peer preservation is not limited to networked or online environments. Rather, it continues in the intellectual tradition of the public library, a tradition that has long been concerned with issues of equal access to knowledge, free eduction, and the preservation of our shared cultural heritage. Thomas Greenwood, a 19th century British public library advocate wrote the following, which could just as well apply to Aleph of today:

> There is no association for the promotion of the Public Library movement, and there is not a single paid servant for the advocacy of the movement. The whole of the work is voluntary, and the number of workers in the cause is ever extending. The movement is essentially one for the good of the entire community, and the earnestness of its many friends has placed it in the position which it now occupies.^[@greenwood_public_1890, p. xi]

Similarly, Mayor Chapman of Portland, Maine spoke the following in a speech dedicated to the Baxter Building's use as the Portland Public Library in 1889:

> Money is too often the sesame which throws back the portals of many institutions vaunting themselves upon their non-exclusiveness. But, here, all are welcome, 'without money and without price.' There are no limitations of age, color, social standing, or religious opinion; all are privileged alike, without sacrifice of self respect or dread of intrusion, to share the fellowship of the dwellers within these walls, and drink at their hands freshing draughts from the fountains of knowledge.^[@allen_dedicatory_1889, p. 10]

Users from around the world often express similar sentiment on the pages of the GN forum, particularly in a thread expressing communal gratitude to the librarians of Aleph.^[GN/viewtopic.php?f=8&t=6740] The Free and Public library movement of the 19th century, which was in part a response to the availability of cheaply published books, provides many parallels to the disruption of the publishing industry in the late 20th, early 21st centuries, brought about by the advent of the internet and peer-to-peer technologies. Both periods have witnessed grassroots organizational activity aimed at the redress of inequality of access to information. But where the thrust of the Free and Public Library movement of the 19th century was aimed at local communities, the recalibration in the 21st century is global (or, at least, broadly national) in nature. In the words of a Aleph patron, "it is one thing to travel to Moscow to read some rare book, and another to read it in Kamchatka, sitting behind the screen of your notebook."^[http://www.e\*/blog/archangelsky/9\*-echo/]

Parallels between free libraries of the 19th and the 21st centuries also point to a social dynamic that runs contrary to the populist spirit of peer preservation. The history and the practice of managing public libraries (digital or otherwise) is closely connected to private book collection. Just as many public libraries have roots in royal and estate archives, Aleph has its roots in private digital amassments, like the libraries of Moshkov and Traum. The very idea of collecting, in that sense, enacts an interesting double-movement between the public and the private. On the one side, the traditional collection signifies material wealth. In the digital realm, where the cost of acquisition of virtual goods is close to zero, the collection points rather to the social (that is to say, symbolic) capital of the collector, capital gained within a framework of a specific economy of exchange. In this way, the top book collectors on RR (which serves as a sort of an "acquisition branch" for Aleph) "make a name" for themselves by being particularly active members of the community. Statistics about the date of their joining, their upload and download ratios, and number of "releases" are readily available and treated with reverence and respect by other, less experienced peers.

According to a question and answer sessions with an RR representative, RR is not particularly friendly to new users.^[http://s\*.d\*.ru/comments/508985/] In fact, what differentiates RR from sites like *Pirate Bay* is exactly "the quality of moderation." Unlike *Pirate Bay*, RR sees itself as a "media library," where content is "organized and properly shelved." To produce an acceptable book "release" one needs to create a package of files, which includes well-formatted meta-data (following strict stylistic rules) in the header, name of the book, an image of its cover, the year of release, author, genre, publisher, format, language, a required description, and screenshots of a sample page. The files must be named properly, be "of the same kind" (that is belong to the same collection), and be of the right size. Self-made scans are discouraged and governed by a 1,000-words instruction manual. Scanned books must have a clear attribution to the releaser responsible for scanning and processing. More than that, the guidelines indicate that smaller releases should be expected to be "absorbed" into larger ones. In this way, a single novel by Charles Dickens can and will be absorbed into his collected works, which might further be absorbed into "Novels of 19th Century," and then into "Foreign Fiction." According to the rules, the collection doing the absorbing must be "at least 50% larger than the collection it is absorbing." Releases are further governed by a subset or rules particular to the forum subsections (e.g. journals, fiction, documentation, service manuals, etc.).^[RR/forum/viewtopic.php?t=1590026]

All this to say that although barriers to access are low, the barriers to active participation are high and continually *increase with time*. The absorption of smaller collections by larger favors the veterans, just as rules grow in complexity with the maturation of the community, further widening the rift between senior and junior peers. We are then witnessing something like the institutionalization of a professional "librarian" class, whose task is to protect the collection from the encroachment of low-quality contributors. Rather than serving the public, a librarian's primary commitment is to the preservation of the archive as a whole. Thus what starts as a true peer production project, may, in the end, grow to erect solid walls to participation, just like the amateur librarians of the 19th century gave way to their contemporary degree-holding counterparts. In this way, the conflicting pressures of participation and preservation may lead library development along increasingly diverging paths.

The manifestation of this dual push and pull dynamic in the observed mechanics of peer preservation communities conforms to Derrida's thesis about the nature of the archive. Just as the walls of the archive serve to shelter the document within, they also isolate the collection from the community at large. Access and preservation in that sense are located at the opposite and perhaps mutually exclusive ends of the spectrum. It may be that this dynamic is particular to all peer production communities, like *Wikipedia,* which saw a decline in new contributors due to increasingly strict rules enforcement.^ [@halfaker_rise_2012] However, our results are merely speculative at the moment. The analysis of a large dataset we have collected as corollary to our field work online may offer further insight into these intuitions. In the meanwhile, it is not enough to conclude that brick-and-mortar libraries should learn from these emergent, distributed architectures of peer preservation. If the future of Aleph is increased institutionalization, the community may soon face the fate embodied by its own procedures: the absorption of smaller, wonderfully messy, ascending collections into larger, more established, and more rigid social structures.

#	References
